{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f8400b8-1b03-4ffe-a00f-9e76fedb03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the data things!\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#visualize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#my sql creds\n",
    "from env import get_db_url\n",
    "import os\n",
    "\n",
    "# import text and create_engine from sqlalchemy\n",
    "from sqlalchemy import text, create_engine\n",
    "\n",
    "# for presentation purposes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62489f3a-1f4f-4fe9-8d6e-224915527439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_exists(fn, query, url):\n",
    "    \"\"\"\n",
    "    This function will:\n",
    "    - check if file exists in my local directory, if not, pull from sql db\n",
    "    - read the given `query`\n",
    "    - return dataframe\n",
    "    \"\"\"\n",
    "    if os.path.isfile(fn):\n",
    "        print('csv file found and loaded')\n",
    "        return pd.read_csv(fn, index_col=0)\n",
    "    else: \n",
    "        print('creating df and exporting csv')\n",
    "        df = pd.read_sql(query, url)\n",
    "        df.to_csv(fn)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4e045a-1038-454c-b27e-fafd32fbe9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it only has 900,223 rows and 6 columns\n",
    "def get_aca_data():\n",
    "    \"\"\"\n",
    "    This function will:\n",
    "         get_aca reads in txt file to csv\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"anonymized-curriculum-access.txt\", sep=' ')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "697692ba-ddca-46dc-b3a3-1696cab28503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logs_data():\n",
    "    \"\"\"\n",
    "    This function will:\n",
    "        - from the connection made to the `curriculum_logs` DB\n",
    "            - using the `get_db_url` from my wrangle module.\n",
    "    \"\"\"\n",
    "    # How to import a database from MySQL\n",
    "    url = get_db_url('curriculum_logs')\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM curriculum_logs.logs as l \n",
    "    JOIN curriculum_logs.cohorts as c ON c.id = l.cohort_id;\n",
    "    \"\"\"\n",
    "\n",
    "    filename = 'logs.csv'\n",
    "    df = check_file_exists(filename, query, url)\n",
    "\n",
    "    df = pd.read_sql(query, url)\n",
    "    \n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93be48d-88f0-4620-af49-0ea7994e767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logs1_data():\n",
    "    \"\"\"\n",
    "    This function will:\n",
    "        - from the connection made to the `curriculum_logs` DB\n",
    "            - using the `get_db_url` from my wrangle module.\n",
    "    \"\"\"\n",
    "    # How to import a database from MySQL\n",
    "    url = get_db_url('curriculum_logs')\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM curriculum_logs.logs;\n",
    "    \"\"\"\n",
    "\n",
    "    filename = 'logs1.csv'\n",
    "    df = check_file_exists(filename, query, url)\n",
    "\n",
    "    df = pd.read_sql(query, url)\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "153744b0-ad0e-4222-9bbb-cab616fb0c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating df and exporting csv\n"
     ]
    }
   ],
   "source": [
    "# if you use MySQL we only get 847,330 rows and 15 columns. it use the log.csv\n",
    "df = get_logs1_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d21272f-6125-42d6-85a5-d47da288ad44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_logs2_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# if you use MySQL we only get 847,330 rows and 15 columns. it use the log.csv\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mget_logs2_data\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_logs2_data' is not defined"
     ]
    }
   ],
   "source": [
    "# if you use MySQL we only get 847,330 rows and 15 columns. it use the log.csv\n",
    "df = get_logs2_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84185e1d-2170-4fec-868f-db6976218f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you use MySQL we only get 847,330 rows and 15 columns. it use the log.csv\n",
    "df = get_logs_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3b3962-778a-40d0-af73-c72d5b73b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you use MySQL we only get 847,330 rows and 15 columns. it use the log.csv\n",
    "df = get_logs_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780eec09-404f-408e-bf4e-7abb27f047a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary(df_mysql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ee639-b34f-479b-a479-57021afc5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that show a summary of the dataset\n",
    "def data_summary(df):\n",
    "    # Print the shape of the DataFrame\n",
    "    print(f'data shape: {df.shape}')\n",
    "    # set all the columns names to a lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "    # Create a summary DataFrame\n",
    "    summary = pd.DataFrame(df.dtypes, columns=['data type'])\n",
    "    # Calculate the number of missing values\n",
    "    summary['#missing'] = df.isnull().sum().values \n",
    "    # Calculate the percentage of missing values\n",
    "    summary['%missing'] = df.isnull().sum().values / len(df)* 100\n",
    "    # Calculate the number of unique values\n",
    "    summary['#unique'] = df.nunique().values\n",
    "    # Create a descriptive DataFrame\n",
    "    desc = pd.DataFrame(df.describe(include='all').transpose())\n",
    "    # Add the minimum, maximum, and first three values to the summary DataFrame\n",
    "    summary['count'] = desc['count'].values\n",
    "    summary['mean'] = desc['mean'].values\n",
    "    summary['std'] = desc['std'].values\n",
    "    summary['min'] = desc['min'].values\n",
    "    summary['25%'] = desc['25%'].values\n",
    "    summary['50%'] = desc['50%'].values\n",
    "    summary['75%'] = desc['75%'].values\n",
    "    summary['max'] = desc['max'].values\n",
    "    summary['first_value'] = df.loc[0].values\n",
    "    summary['second_value'] = df.loc[1].values\n",
    "    summary['third_value'] = df.loc[2].values\n",
    "    \n",
    "    # Return the summary DataFrame\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f90b6c-8ad9-4dce-a452-cd492df44821",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a5b69-c51f-4d1d-90a7-232c3dc5593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75dbbb-d79c-473c-98cf-32ca3ed7703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_remove = ['id','slack','deleted_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83690841-788b-4085-bfa6-7bd2e098fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df, col_to_remove):\n",
    "    \"\"\"\n",
    "    This function will:\n",
    "    - take in a df and list of columns (you need to create a list of columns that you would like to drop under the name 'cols_to_remove')\n",
    "    - drop the listed columns\n",
    "    - return the new df\n",
    "    \"\"\"\n",
    "    df = df.drop(columns=col_to_remove)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145cc5f3-82a6-4ff5-88a4-5327da349605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, prop_required_columns=0.5, prop_required_rows=0.75):\n",
    "    \"\"\"\n",
    "    This function will:\n",
    "    - take in: \n",
    "        - a dataframe\n",
    "        - column threshold (defaulted to 0.5)\n",
    "        - row threshold (defaulted to 0.75)\n",
    "    - calculates the minimum number of non-missing values required for each column/row to be retained\n",
    "    - drops columns/rows with a high proportion of missing values.\n",
    "    - returns the new df\n",
    "    \"\"\"\n",
    "    \n",
    "    column_threshold = int(round(prop_required_columns * len(df.index), 0))\n",
    "    df = df.dropna(axis=1, thresh=column_threshold)\n",
    "    \n",
    "    row_threshold = int(round(prop_required_rows * len(df.columns), 0))\n",
    "    df = df.dropna(axis=0, thresh=row_threshold)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba75da8-d12e-423c-9711-17ff1b36f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df, col_to_remove, prop_required_columns=0.5, prop_required_rows=0.75):\n",
    "    \"\"\"\n",
    "    This function will:\n",
    "    - take in: \n",
    "        - a dataframe\n",
    "        - list of columns\n",
    "        - column threshold (defaulted to 0.5)\n",
    "        - row threshold (defaulted to 0.75)\n",
    "    - removes unwanted columns\n",
    "    - remove rows and columns that contain a high proportion of missing values\n",
    "    - returns cleaned df\n",
    "    \"\"\"\n",
    "    df = remove_columns(df, col_to_remove)\n",
    "    df = handle_missing_values(df, prop_required_columns, prop_required_rows)\n",
    "    \n",
    "    # converts int to datetime\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    \n",
    "    # rename the numbers for names\n",
    "    df.program_id = df.program_id.replace({1: 'full_stack_java_php', 2: 'full_stack_java_java', 3: 'datascience', 4: 'front_end_web_dev'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eef0fa8-6106-465f-9102-692b16b9789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_prep(df, col_to_remove, prop_required_columns=0.5, prop_required_rows=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4825849c-1674-45ab-908d-72c97d454eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't add it to the function. It will remove more than the nulls\n",
    "# drop any nulls in the dataset\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c2475-4f6f-4b53-a0b0-83e536cbbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925adb42-f924-4c6c-a66f-f6ff8f69a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e44cad8-ca84-4fdf-8e3f-2b12c0616bae",
   "metadata": {},
   "source": [
    "## 4. Is there any suspicious activity, such as users/machines/etc accessing the curriculum who shouldnâ€™t be? Does it appear that any web-scraping is happening? Are there any suspicious IP addresses?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff4eec-14b7-4c27-b444-332590f1e5d6",
   "metadata": {},
   "source": [
    "## count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba164bb-1d73-490f-935d-a804a8a323c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate count\n",
    "def count(df, column):\n",
    "    return df[column].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731a981-a407-4151-a7e9-10836b06829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ip count\n",
    "count(df, 'ip').sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428f9d18-caff-403f-9a60-d75ad6b76eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ip count\n",
    "count(df, 'user_id').sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caac2fe-4a6b-4c1a-8dbb-7425dc3e3e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_user_df_prep(df, user):\n",
    "    df = df[df.user_id == user].copy()\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df = df.set_index(df.date)\n",
    "    df = df.sort_index()\n",
    "    pages_one_user = df['path'].resample('d').count()\n",
    "    return pages_one_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf170f7-facd-483b-bea1-27fda8644be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pct_b(pages_one_user, span, k, user):\n",
    "    midband = pages_one_user.ewm(span=span).mean()\n",
    "    stdev = pages_one_user.ewm(span=span).std()\n",
    "    ub = midband + stdev*k\n",
    "    lb = midband - stdev*k\n",
    "    \n",
    "    my_df = pd.concat([pages_one_user, midband, ub, lb], axis=1)\n",
    "    my_df.columns = ['pages_one_user', 'midband', 'ub', 'lb']\n",
    "    \n",
    "    my_df['pct_b'] = (my_df['pages_one_user'] - my_df['lb'])/(my_df['ub'] - my_df['lb'])\n",
    "    my_df['user_id'] = user\n",
    "    return my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2ca89-cf71-44c5-bf3c-11cb7f5968ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bands(my_df, user):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    ax.plot(my_df.index, my_df.pages_one_user, label='Number of Pages, User: '+str(user))\n",
    "    ax.plot(my_df.index, my_df.midband, label = 'EMA/midband')\n",
    "    ax.plot(my_df.index, my_df.ub, label = 'Upper Band')\n",
    "    ax.plot(my_df.index, my_df.lb, label = 'Lower Band')\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_ylabel('Number of Pages')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4223b-1927-4aab-a250-b4e87f328006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_anomalies(df, user, span, weight, plot=False):\n",
    "    pages_one_user = one_user_df_prep(df, user)\n",
    "    \n",
    "    my_df = compute_pct_b(pages_one_user, span, weight, user)\n",
    "    \n",
    "    if plot:\n",
    "        plot_bands(my_df, user)\n",
    "    \n",
    "    return my_df[my_df.pct_b>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb226443-9ed0-48c6-8823-97907c56b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.ip == '97.105.19.58']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d440ba-a87e-4baa-9533-0122aa79a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=570\n",
    "span=720\n",
    "k=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57884f93-826a-4c06-8e42-e4cef9934a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_anomalies(df, user, span, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e408937-3d20-424e-baa0-85158dcd34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_anomalies(df, span, k):\n",
    "    \"\"\"\n",
    "    Finds anomalies for all users in the provided DataFrame over a specified span \n",
    "    of time. An anomaly is defined as a value that is above the upper band, which \n",
    "    is calculated using the Exponential Moving Average (EMA or midband) and a \n",
    "    specified number of standard deviations.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame, which should include a 'user_id' \n",
    "                           and a 'date' column.\n",
    "        span (int): The span of the window for the EMA calculation, representing \n",
    "                    the number of time periods (e.g., 7 for a week, 30 for a month).\n",
    "        k (int): The number of standard deviations to use when calculating the \n",
    "                 upper and lower bounds.\n",
    "\n",
    "    Returns:\n",
    "        anomalies (pd.DataFrame): A DataFrame containing the anomalies for all users. \n",
    "                                   Each row includes the original page visit data, \n",
    "                                   the EMA (midband), the upper and lower bounds (ub and lb), \n",
    "                                   the %b value (pct_b), and the user ID. Only rows where \n",
    "                                   pct_b > 1 (indicating an anomaly) are included. If no \n",
    "                                   anomalies are found for a user, no rows for that user \n",
    "                                   will be included in the DataFrame.\n",
    "    \"\"\"\n",
    "    anomalies = pd.DataFrame()\n",
    "\n",
    "    for u in df.user_id.unique():\n",
    "        one_user = find_anomalies(df, u, span, k)\n",
    "        anomalies = pd.concat([anomalies, one_user])\n",
    "\n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536d432-95c8-4ab1-a6a0-46b22782bb48",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_find_all = find_all_anomalies(df, span, k)\n",
    "df_find_all\n",
    "df_find_all.sort_values(by='pages_one_user', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23d9ee-128d-4342-8add-40a7050eaf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.ip == '97.105.19.58']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf7bf5-03a0-4cd7-b85e-9e6216eaf0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.user_id == 11].date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845c822-de31-40e2-bd54-3bd7dac95bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11 = df[(df.user_id == 11) & (df.date == '2020-07-22')]\n",
    "df_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd162c77-f9df-4e70-aeb7-d8d20ae4ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60,8))\n",
    "df_11.time.hist()\n",
    "plt.xticks(rotation =45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3480ac8-1993-493d-be3d-55956be5e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.user_id == 11) & (df.date == '2020-07-22')].start_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf82155-bfb7-4b28-ab78-4518873a30a7",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851eca20-3bed-454b-8d06-3ce81bc7ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate frequency\n",
    "def frequency(df, column):\n",
    "    return df[column].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d168e-44bb-4fb2-af6b-b650fe6adfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency(df, 'user_id').sort_values(ascending =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae852e7-5d5c-4a68-8e19-df73b5401e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency(df, 'ip').sort_values(ascending =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88dca9d-f23b-496d-a222-a2b3ee4bbffa",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df217d66-ca54-4ca5-a8f6-9290e63073b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to visualize count\n",
    "def visualize_count(df, column):\n",
    "    df[column].value_counts().sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218d2e49-88dd-40dc-9fab-2202534cba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_count(df, 'ip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687911cc-9d43-43ba-85a2-ed5f20c540c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the count and percent for each IP\n",
    "ip_count_df = df['ip'].value_counts().reset_index().rename(columns={'index': 'ip', 'ip': 'count'})\n",
    "ip_count_df['percent'] = (ip_count_df['count'] / df.shape[0]) * 100\n",
    "ip_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22956df4-9536-436f-93a4-17cfdd044405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to visualize count\n",
    "def visualize_percent(df, column):\n",
    "    ip_count_df.set_index(column).percent.sort_values().plot.barh()\n",
    "\n",
    "    plt.title('percent of each ip address')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e4a20-a4ae-4665-9786-1a19d2db3132",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_percent(df, 'ip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ff139-6422-4c33-a429-d4a5e36107dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556faef7-bb8b-44df-a8c6-a226f5606555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7210f834-bf0b-4265-9e52-0bb2cc7d7f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
